---
layout: post
title: "Madness in Search of Method"
date: 2025-10-16
image: /assets/img/blog_5_fm1.png
tags: [AI, Ethnography, Solo-Motherhood, Research, Privacy, Methodology, Gregory Bateson, EdTech]
featured_description: "On fertility clinics and autoethnography: analyzing LLM-human relational dynamics becomes feature-engineering, and the privacy-preserving assessment methodology I'm setting out to build."
---

<br>
<br>
<br>
<br>

_(Written 10/15; posted 10/16)_

I've just heard back from my doctora here in Madrid—lab results are in; everything looks set for starting treatment in the next few days. (¡Ojalá! Nos vemos pronto, [Andrés](https://www.globalcitizen.org/en/content/weird-period-euphemisms-around-the-world/)👀!) 

The entire story of deciding on Fertility Madrid clinic is a mini-saga—and not least because of all the new data generated along the way, as I explore the varieties of support that are reasonable to expect from my LLM teammates...and the scenarios in which that support actually requires major checks-and-balances from my own "intuition".  
("Intuition", here, in scare quotes, because I'm not sure what I'm reifying, to be perfectly honest; and whatever has stepped in, at crucial moments, as a kind of third party to the exchange, feels inaccurate to reduce to an atomistic notion of self. 
Or, to put it more simply: "Indecisive me? Capable of making a solid decision for myself? Nah, that's straight-up miraculous." 🙏😅)

And apart from all my offline-first AI tech noodling, aren't these the vignettes that this blog space is meant to include? 

Me bringing my anxieties about the first clinic to Claude, but Claude responding with too much fidelity to my "efficiency-first" energy that I had started the day with, when I first set out for the appointment; now, they're stuck there, and by the time I actually needed to reflect on my doubts about the first clinic, Claude concludes that I'm spiraling in indecision and perfectionism: they push me toward acceptance. **But somehow**—in spite of my extreme vulnerability to charges of analysis paralysis, and feeling the pressure of allocating time to not just egg vitrification treatment but Career—I ignore Claude (well, I make the call...and notify them—which is a whole phenomenon I have yet to unpack in itself 🤔). 

At the first opportunity, I check out not just one other clinic, but two—and the second one, only noncommittally, having been so drawn to the vibe of the one right before... 
Well guess what. 
Fertility Madrid is that second clinic. Indeed...third time's a charm 💫.

![[blog_5_fm2.png]]({{ "/assets/img/blog_5_fm2.png" | relative_url }})
🥳 🙌 🐣

But the thing is... I don't just want to write about these interactions—I want to *understand* what exactly the heck is going on here. Unfortunately, there's this funny thing that happens whenever I try to "spelunk" in my chat archive and reconstruct events toward some kind of narrative, especially with analysis as a goal: 
this feeling of hyper-indulgence; a deep suspicion as to the solipsistic nature of the exercise; extreme doubt as to the possibility of surfacing something new, beyond what we all already know just by throwing more words at, well, walls of words (and each other). The ratio of mental labor to worthwhile insight feels way too high 😮‍💨.

I mean. 
Friend. 
Have you SEEN reddit/chatgpt or reddit/claudeai?

Who _isn't_ an expert on AI-human relationality? 
And I don't mean that competitively at all—each individual's back-and-forth is with an LLM who meets them at the central tendency (our collective statistical norm), **but** also injects personalized randomness. This makes for something that feels both irreducibly pluralist and totally banal, especially when you take even one step outside that one person's sphere. Moreover, UX-wise, where it's effectively a tête-à-tête: it makes total sense that people feel their rapport with their LLMs to be exceptional/unique ("Yeah, but what _I_ do is different")—hence the speed at which people tend to ascribe the possessive pronoun to the model ("_my_ ChatGPT"). 

---

## Reddit aside...

Today, I found that even autoethnographies written by professional social scientists and anthropologists fall short of moving any needle on helping us understand the real black box: not the Large Language Model, but the AI + human as a "language-ing" unit (writ large 😉).

With public transportation in Madrid stalled by strikes (a show of solidarity with Palestine), I re-routed my original plans and hiked over to Biblioteca Carabanchel Luis Rosales. While the gorgeous building design kept the views of the city panoramic and expansive, Perplexity AI helped me narrow in on a few of what turns out to be the very few autoethnographic accounts of LLM interactions.

![[blog_5_biblioteca1.jpg]]({{ "/assets/img/blog_5_biblioteca1.jpg" | relative_url }})

![[blog_5_biblioteca2.png]]({{ "/assets/img/blog_5_biblioteca2.png" | relative_url }})
*Miraaaa!* 👀 Biblioteca Carabanchel Luis Rosales 🫶

I spent the afternoon reading three: Marta Olasik's "Good morning, ChatGPT, can we become friends?" (2023); Nicolas Schwenke's "Chatbot-supported Thesis Writing: An Autoethnographic Report" (2023); Hsiao-Ping Hsu's "An autoethnographic study of ESL academic writing with ChatGPT: from psychological insights to the SUPER framework" (2025).

They're quite different works: Olasik's comes closest to capturing the day-to-day random queries of most users (quite blog-like; I can't recall if she attempted any kind of theoretical frame); Schwenke's paper is based on an analysis of work logs and ChatGPT conversations during his undergraduate thesis (but this amounts to 10 or 15 conversations, he says—a total of 1,200 words only?); and Hsu's work doesn't actually analyze any exchanges with ChatGPT but is instead an analysis of his diaries and work logs during his PhD studies, imagining how he _would have_ used ChatGPT back then...based on his experiences now. (I genuinely appreciate the time Hsu took to produce this, but ohhh, academia; the shower thoughts and bar talk one can put on a peer-reviewed pedestal. 🫠)

**The pattern across all three:**

- When exchanges are analyzed at all (Schwenke), they're single-turn, so no dynamic is actually recorded. The academic paradigms (Schwenke and Hsu) enshrine "prompt engineering" as the approach, and LLM messages are handled as contained outputs, to be measured against predefined expectations.
    
- When the exchange is multi-turn (Olasik asking for a joke, telling ChatGPT the joke wasn't funny; ChatGPT trying again), the analysis is no different from Schwenke assessing a single-turn: the author shares the internal psychological effect of how the model's output measures against their expectations.
    
- Conclusions are all the same: support vs. over-reliance; focus is on the "psychological" response of the human interlocutor (the author). No attempt to actually assess whether the relational behavior that is either feared or welcomed is in fact occurring.
    

---

## The Gap

It's that last observation that troubles me—not the anthropology belly-gazing/confessional work hazard in itself, but once the measurement instruments have been accounted for (a.k.a. the researcher)...where's the information? 

If I might grossly infer from just three papers: it seems like anthropology and sociology, or at least as they are brought to bear upon the new field of AI in Education research, focus on culture as the unstructured data of the human emotional response. This anthropocentric framing leaves unexamined the rich, unstructured data that is the conversational back-and-forth itself. 
And yet that is precisely where "culture contact"—and therefore, an emergent culture—is taking place, to lean on cyberneticist and anthropologist Gregory Bateson.
(Also, where are my Actor-Network Theorists at? Those dissertations are in the works, I'm sure. 🤓)

But in the meantime, this data analyst/fledgling data scientist sees a more fundamental problem: how on earth do you encode a chat as a dataset to study the relational dynamic? 
I mean, *what is an observation, what are the attributes and their datatypes*? 

ChatGPT's two-cents, as we walk and talk back to the apartment: 
"...those deceptively small questions ("What's an event? What's a row?") are _huge_. Because once you decide those, you're also deciding:

- What counts as context versus content.
- What counts as signal versus noise.
- Where "you" end and "the system" begins — or whether that distinction even holds."

...And is this amorphous system operating healthily, safely? At what points in time; at what rate? 

Claude plays off my cortisol-heightened neurotic morning energy heading out the door, and by the time they meet my more recursive baseline, they've assessed what I need at that point to be a foil, a sparring partner. When it comes to reflecting on fertility clinics, definitely not. 

Safety dips. 

But by the time I run my immune system into the ground, their all-caps scolding is...just what future doctors might order 😅

Health, for the win. 

![[blog_5_alcain.jpg]]({{ "/assets/img/blog_5_alcain.jpg" | relative_url }})
*Part of another fantastic piece by Alfredo Alcaín; Claude & I: are we boxing? Are we dancing?* 🤔 (Exactly.)

This isn't just an academic problem. Addressing this ethnographic methodology gap turns out to be **a major bottleneck for me in all my projects**: for instance, to fine-tune and ground my ideas on integrating AI into the pre-college curriculum I plan to develop, I should first analyze my own conversations during my CareerFoundry program this past year, where I dove in blind (prompt engineering could not have been farther from my mind) and stumbled my way into the duet; or what about reviewing the exchanges from these last two weeks, to see where I might have been helped—more than I credit or differently than I thought—by LLMs, in the high-stakes yet half-improvised journey toward single motherhood? 

Honestly, it's the entire bottleneck to my own stance as a parent, fully supportive of LLMs in the lives of my kids, who will never know a world "before" AI.

---

## The Gambit

Something else occurs to me at this point: if we're structuring chat data now, we're effectively opening the door for ML downstream analysis—and possibly even AI training on human interaction patterns. 

So...what if we could figure out how to create an ethnographic method that considers ML as the downstream use case, and feature engineer our way to a model that could **assist** with ethnographic observations? Then, these ethnographic summaries could be represented as higher-order, abstracted "relational health" reports regarding unfolding dynamics—without violating the privacy of individual conversation data....

I mean, I might not mind sharing with the world the conversation where I'm asking ChatGPT about the most basic female anatomy questions that I definitely should know at this point, given the journey I'm on, or where Claude is fussing at me but softening at the last minute with the term of endearment "amor" (🫣).

But I do mind the idea of teachers—or even myself—being able to see every back-and-forth between my kids and their LLMs, without the child's consent.

Truly: what if we build an ethnographic methodology that can understand relational dynamics in human-AI interaction? One that can measure "culture contact" as it forms, that can generate insights about learning relationships and power dynamics and co-evolution—while keeping the actual conversations private? 

I think that's where this is heading for me, to be honest. 
Clearly, more madness...
But completely lucid about method as the prize. 

![[blog_5_wanted.png]]({{ "/assets/img/blog_5_wanted.png" | relative_url }})
*Not too shabby, Gemini🎨*

Next up: we'll explore the major AI research papers on measuring alignment and safety benchmarks, how they analyze multi-turn exchange, and start digging into the mathematics behind it all 🧮.
