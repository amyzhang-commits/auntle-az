---
layout: post
title: "Knock Knock!"
date: 2025-10-25
image: /assets/img/blog_6_olive.jpg
tags: [HCI, Human-AI Interaction, Metrics, Research Methods, Hot Potato Theory, Fertility Journey, Conceptual Framing]
featured_description: "From a self-roast to cooking up a plan: why I'm diving into Human-Computer Interaction research to find metrics that capture the messy, meaningful space between 'finding' and 'giving' the right answer."
---

<br>
<br>
<br>
<br>

**Knock knock.**  
— _Who’s there?_  
— **Olive.**  
— _Olive who?_  
— **Olive** getting free olive oil from the pharmacy because I just dropped major _dinero_ on gonadotropins. 😌  
(Mom joke flex: accomplished.)

<img src="{{ "/assets/img/blog_6_olive.jpg" | relative_url }}" alt="olive oil gift" style="max-width: 60%; height: auto; display: block; margin: 0 auto;">
*Fig A: 👁️❤️🫒*

I think a lot has happened this week, but frankly, all I can recall is the daily wrestle with my amygdala, cortisol crescendoing until the clock strikes 9pm, auto-jabbings o'clock. 💉💉 

(Okay, I'm being a little dramatic about that mental hurdle; by day 2, I was already scripting in Spanish how to sheepishly admit to the nurse that she was right: *al fin, soy valiente!* 😅 But seriously, to give you a sense of how much I hate needles: I don't even carry around an epipen for my actual life-threatening food allergy. 😬)

![[blog_6_agujas.jpg]]({{ "/assets/img/blog_6_agujas.jpg" | relative_url }})
🦈😰

There is one other memory emerging from the endocrine-cranked mist: the intensely messy, haphazard process of moving forward on the epiphany I shared in the last blog post. Actually, forget for a moment building on the epiphany-- even just moving forward *from* the last post was a staggered affair. 

## Hot Potato Fail 

Last week, I had summarized the issue I was noticing as follows (* preparatory cringe *): 

> "If I might grossly infer from just three papers: it seems like anthropology and sociology, or at least as they are brought to bear upon the new field of AI in Education research, focus on **culture as the unstructured data of the human emotional response**. This anthropocentric framing leaves unexamined the rich, unstructured data that is **the conversational back-and-forth itself**. And yet that is precisely where **“culture contact”**—and therefore, **an emergent culture**—is taking place, to lean on cyberneticist and anthropologist Gregory Bateson. (Also, where are my **Actor-Network Theorists** at? Those dissertations are in the works, I’m sure. 🤓)"

⁉️ Where in the sesquipedalian sewage system did that come from?? 🚮 

(*Also, just gotta love how I'm accusing anthropology of anthropocentrism (like, duh?), and moreover, without clarifying how I'm conceptualizing culture, it would be totally fair for someone to say, "Uhm, Amy, if the chat is 'culture contact', aren't you anthropomorphizing LLMs as being like a people?"* 🙄)

...Look, something I'm trying to push myself to do, specifically through this practice of blogging, is to learn how to write around (?) my uncertainty. Otherwise, sharing the journey, where I'm at as I build, would be impossible. (Perhaps my uncertainty will encounter the missing puzzle piece of someone else's certainty? 🤞 Perhaps the uncertainty can help someone else's uncertainty feel a little lighter 🫶 Just...don't ask me right now, not even half-way through this week's attempt. 🫠)

Here, the uncertainty radiating out of every space mark would seem to be that of how to articulate a rather dense set of ideas around technology, culture, and language that underpin my entire approach to AI and ethics-- ideas that come from not exactly the most mainstream of theorists when it comes to the general public. 
Furthermore, these ideas have probably been digested and metabolized in weird ways by my academic, scavenger brain. 🦝 

The above game of hot potato falls flat because I hastily/sloppily throw out hints of: 
- **Culture as practice vs. attribute:** culture is not a fixed property but a shifting set of doings (_Culture Techniques — B. Siegert_).
- **Non-human actants:** tools, code, and systems can exert agency in networks, which makes LLMs participants that shape outcomes without being “people” (_Actor-Network Theory — B. Latour_).
- LLMs as **statistical-consciousness-aggregates**: not people, not conscious, not bearers of a capital-C Culture... **but**—
- ...because there _is_ explicit, word-based communication and dynamic feedback (learning and adaptation across ontological divides), conversational exchanges can still be treated as a kind of bilateral **culture contact** (_Cybernetic Theory; Deutero-Learning — G. Bateson_).

However, when these potatoes are justifiably flung back at me as Questions...I have to let them fall. 😔

Because now's not really the time to expound on the theoretical scaffolding, frankly. 

It's time to test whether it can even hold the weight of the build-- by informing the design of metrics. ⏰ 🏗️ 📐

<img src="{{ "/assets/img/blog_6_molinos.jpg" | relative_url }}" alt="Me and Don Q, seeing things more clearly" style="max-width: 60%; height: auto; display: block; margin: 0 auto;">
*Fig B: Don Q & I, getting a much better sense of what we're actually tackling*

---

## The REAL Gap

At this point, I must confess: when it comes to taking unstructured, qualitative notes-from-the-field data, and distilling them into quantitative metrics that can triangulate **even as** they reduce...I am at a bit of a loss.

This, I've realized, is _the_ real gap between the theory and the build: how do we move from rich, messy human-AI conversation logs to numbers that still mean something? And it's not a gap out in the field—just in my current knowledge.

It turns out, of course, there's an entire field obsessed with exactly this kind of translation—one I hadn't properly explored before: _Human-Computer Interaction Studies._ So this past week, I took the time to read some papers from this arena; this week, I'll be putting together a little slide-deck overview.

Just a sneak preview: there are some **truly clever experimental precedents**, even if their research questions don't map perfectly onto mine—things like:

- _Remote Clique metrics_ for measuring topic diversity across exchanges;
- _Markov Chain Monte Carlo algorithms_ to peek at human-AI semantic alignment;
- and some good old-fashioned psychometric validation (hello, _Cronbach's alpha_) before busting out the ANOVA for hypothesis testing.

10 fresh-out-the-oven papers, from 2024-2025! (Thanks, Perplexity AI; and preemptively, Notebook LM, Claude, and ChatGPT as I dive into the details 🦾💪) Gonna catch all these hot potatoes and make us some fries 🍟

---
## ...And before we go this week: mini-updates

**📊 The ChatGPT Archive Project**

To date: 435 separate conversation windows with ChatGPT, spanning December 31, 2023 to October 24, 2025. I've exported all of them as markdown files and started playing around with parsing.

Cannot recommend this plugin enough: [ChatGPT Exporter](https://chromewebstore.google.com/detail/chatgpt-exporter-chatgpt/ilmdofdhpnhffldihboadndccenlnfll). Elegant solution—it takes the HTML from the conversation window (right click > Inspect > Console) and extracts the structure for you. 🙏

**🏥 LLMs, Serendipity, and Finding Fertility Madrid**

As I continue reflecting on the clinic search process, the interplay between researching with LLMs from my armchair, so to speak, and research that could only have been accomplished by going out and taking my chances in the world, becomes ever more striking...and subtle.

Back in the US, I uploaded pricing PDFs to Claude and asked in the most general way what they thought. Claude picked out details, categorized pros and red flags, and gave an overall assessment of "clarify these, but overall, it looks transparent."

Going with their assessment would have been a huge misdirect. I needed to actually _talk_ to different clinics to realize the first one had a catch: "up to 10 eggs included, extra charge for each one over." This sounds reasonable until you learn—as I did at another clinic—that the target is always 12-15 eggs per retrieval cycle.

**But here's the thing:** until Claude, I had not explicitly raised _pricing transparency_ as something to look for—as a concept to be conscious of. Sure: affordability. But _pricing transparency_ covers a crucial element of 'fairness' that affordability doesn't, even when I combined my "affordability" thinking with "high quality". The question pricing transparency captures is Trust.

So, while Claude couldn't verify the fact, they surfaced the framework. And when the real information arrived (through human conversation), I was ready to recognize it and make the right decision.

Where "conceptual framing" falls between "finding" and "giving" the right answer: that's exactly the kind of nuance I want to measure in human-AI interaction.
